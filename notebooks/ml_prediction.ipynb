{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d16ef32-8d41-499b-961a-5cf0c17df360",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efbe4c1-653d-416c-bff9-0b31c8c8672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7234a38-135a-46fb-a0b3-f93faf2c3823",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c84ddd-2a4d-4c18-8227-edaabe9f9075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Job_Role</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Years_of_Experience</th>\n",
       "      <th>Work_Location</th>\n",
       "      <th>Hours_Worked_Per_Week</th>\n",
       "      <th>Number_of_Virtual_Meetings</th>\n",
       "      <th>Work_Life_Balance_Rating</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Mental_Health_Condition</th>\n",
       "      <th>Access_to_Mental_Health_Resources</th>\n",
       "      <th>Productivity_Change</th>\n",
       "      <th>Social_Isolation_Rating</th>\n",
       "      <th>Satisfaction_with_Remote_Work</th>\n",
       "      <th>Company_Support_for_Remote_Work</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Sleep_Quality</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP0001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Depression</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP0002</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>Increase</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP0003</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>No Change</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP0004</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Depression</td>\n",
       "      <td>1</td>\n",
       "      <td>Increase</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP0005</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Burnout</td>\n",
       "      <td>1</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Employee_ID  Age  Gender  Job_Role  Industry  Years_of_Experience  \\\n",
       "0     EMP0001   32       2         2         3                   13   \n",
       "1     EMP0002   40       0         0         4                    3   \n",
       "2     EMP0003   59       2         6         1                   22   \n",
       "3     EMP0004   27       1         6         2                   20   \n",
       "4     EMP0005   49       1         5         0                   32   \n",
       "\n",
       "  Work_Location  Hours_Worked_Per_Week  Number_of_Virtual_Meetings  \\\n",
       "0        Hybrid                     47                           7   \n",
       "1        Remote                     52                           4   \n",
       "2        Hybrid                     46                          11   \n",
       "3        Onsite                     32                           8   \n",
       "4        Onsite                     35                          12   \n",
       "\n",
       "   Work_Life_Balance_Rating  Stress_Level Mental_Health_Condition  \\\n",
       "0                         2             2              Depression   \n",
       "1                         1             2                 Anxiety   \n",
       "2                         5             2                 Anxiety   \n",
       "3                         4             0              Depression   \n",
       "4                         2             0                 Burnout   \n",
       "\n",
       "   Access_to_Mental_Health_Resources Productivity_Change  \\\n",
       "0                                  0            Decrease   \n",
       "1                                  0            Increase   \n",
       "2                                  0           No Change   \n",
       "3                                  1            Increase   \n",
       "4                                  1            Decrease   \n",
       "\n",
       "   Social_Isolation_Rating  Satisfaction_with_Remote_Work  \\\n",
       "0                        1                              2   \n",
       "1                        3                              1   \n",
       "2                        4                              2   \n",
       "3                        3                              2   \n",
       "4                        3                              2   \n",
       "\n",
       "   Company_Support_for_Remote_Work  Physical_Activity  Sleep_Quality  Region  \n",
       "0                                1                  1              1       2  \n",
       "1                                2                  1              1       1  \n",
       "2                                5                  1              2       3  \n",
       "3                                3                  1              2       2  \n",
       "4                                3                  1              0       3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('../data/clean/cleaned_data2.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd74c13-f20d-4a17-ae41-04248c4f2ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (5000, 19)\n",
      "Target shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Define the features and target\n",
    "features = df.drop(columns=['Mental_Health_Condition'])  # Dropping the target column from features\n",
    "target = df['Mental_Health_Condition']  # Target column\n",
    "\n",
    "# Check the shapes to ensure proper splitting\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Target shape:\", target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d893e-93aa-4f4c-8b4a-fffbca5add27",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435e48e1-61fb-4a2d-bf04-e7f13be5c2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4000, 19)\n",
      "X_test shape: (1000, 19)\n",
      "y_train shape: (4000,)\n",
      "y_test shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the split data to verify the split\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d35448-ff65-41a5-b04c-2794723f8fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Employee_ID', 'Age', 'Gender', 'Job_Role', 'Industry',\n",
      "       'Years_of_Experience', 'Work_Location', 'Hours_Worked_Per_Week',\n",
      "       'Number_of_Virtual_Meetings', 'Work_Life_Balance_Rating',\n",
      "       'Stress_Level', 'Access_to_Mental_Health_Resources',\n",
      "       'Productivity_Change', 'Social_Isolation_Rating',\n",
      "       'Satisfaction_with_Remote_Work', 'Company_Support_for_Remote_Work',\n",
      "       'Physical_Activity', 'Sleep_Quality', 'Region'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85687be-65b7-4359-9baf-360374d7fa72",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f86d5810-c489-499d-a94d-d0a398cf5266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_encoded shape: (4000, 13)\n",
      "X_test_encoded shape: (1000, 13)\n"
     ]
    }
   ],
   "source": [
    "# List of categorical columns that need encoding\n",
    "categorical_cols = [ 'Job_Role'] \n",
    "\n",
    "# Adjust the list of categorical and numerical columns based on X_train\n",
    "categorical_cols = ['Job_Role', 'Gender']  # Ensure these columns exist in X_train\n",
    "numerical_cols = ['Years_of_Experience', 'Hours_Worked_Per_Week']  # Modify as necessary\n",
    "\n",
    "\n",
    "# Create ColumnTransformer for encoding categorical features and scaling numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_cols), # OneHotEncode categorical features\n",
    "        ('num', StandardScaler(), numerical_cols) # Scale numerical features\n",
    "    ])\n",
    "\n",
    "# Apply transformations to training and testing sets\n",
    "X_train_encoded_np = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded_np = preprocessor.transform(X_test)\n",
    "\n",
    "# Check the shape after encoding\n",
    "print(\"X_train_encoded shape:\", X_train_encoded_np.shape)\n",
    "print(\"X_test_encoded shape:\", X_test_encoded_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5673ce-0fde-49ee-834b-b2cbaa3d2636",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a968d-9670-4878-a073-f80387ed0933",
   "metadata": {},
   "source": [
    "## Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0b40d726-15ae-4308-b756-c0bb93d01918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12818081 -0.22074195 -0.0991394  -0.1700956  -0.00208136  0.00863582\n",
      "  -0.15614212 -0.27316124 -0.24259273 -0.16583498 -0.08615647 -0.03221359\n",
      "  -0.02504118]]\n",
      "Logistic Regression Accuracy: 0.73\n",
      "Logistic Regression Train Accuracy: 0.75\n",
      "Logistic Regression Test Accuracy: 0.73\n",
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      1.00      0.86      2991\n",
      "        True       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.75      4000\n",
      "   macro avg       0.37      0.50      0.43      4000\n",
      "weighted avg       0.56      0.75      0.64      4000\n",
      "\n",
      "Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      1.00      0.84       731\n",
      "        True       0.00      0.00      0.00       269\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.37      0.50      0.42      1000\n",
      "weighted avg       0.53      0.73      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg.fit(X_train_encoded_np, y_train)\n",
    "\n",
    "# Predict the target on both the training and test sets\n",
    "y_pred_train_log_reg = log_reg.predict(X_train_encoded_np)  # Predictions on training set\n",
    "y_pred_test_log_reg = log_reg.predict(X_test_encoded_np)    # Predictions on test set\n",
    "\n",
    "# Print the coefficients (optional)\n",
    "print(log_reg.coef_)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_test_log_reg)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print accuracy for both training and test sets\n",
    "print(f\"Logistic Regression Train Accuracy: {accuracy_score(y_train, y_pred_train_log_reg):.2f}\")\n",
    "print(f\"Logistic Regression Test Accuracy: {accuracy_score(y_test, y_pred_test_log_reg):.2f}\")\n",
    "\n",
    "# Print classification report for training and test sets, setting zero_division to handle undefined metrics\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_pred_train_log_reg, zero_division=0))\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_report(y_test, y_pred_test_log_reg, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e1df4-2670-4fae-b6b3-5baea28d0bee",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0559b13f-922d-40bb-b8de-5faa189ddca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00868225 0.00870478 0.00950734 0.00839492 0.00896581 0.00758439\n",
      " 0.00871228 0.00955583 0.00944683 0.00984495 0.00875469 0.43706406\n",
      " 0.46478188]\n",
      "Random Forest Accuracy: 0.38\n",
      "Random Forest Train Accuracy: 0.98\n",
      "Random Forest Test Accuracy: 0.38\n",
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.98      0.97      0.97      1009\n",
      "     Burnout       0.98      0.98      0.98      1997\n",
      "  Depression       0.97      0.96      0.97       994\n",
      "\n",
      "    accuracy                           0.98      4000\n",
      "   macro avg       0.98      0.97      0.97      4000\n",
      "weighted avg       0.98      0.98      0.98      4000\n",
      "\n",
      "Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.27      0.25      0.26       269\n",
      "     Burnout       0.48      0.55      0.51       479\n",
      "  Depression       0.26      0.20      0.23       252\n",
      "\n",
      "    accuracy                           0.38      1000\n",
      "   macro avg       0.33      0.33      0.33      1000\n",
      "weighted avg       0.37      0.38      0.37      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RandomForest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_encoded_np, y_train)\n",
    "\n",
    "# Predict the target on the test data\n",
    "#y_pred_test_rf = rf_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Predict on both training and test sets\n",
    "y_pred_train_rf = rf_model.predict(X_train_encoded_np)\n",
    "y_pred_test_rf = rf_model.predict(X_test_encoded_np)\n",
    "\n",
    "\n",
    "# This tells you how important is each column in the final model prediction\n",
    "print(rf_model.feature_importances_)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
    "\n",
    "# Print accuracies for both sets\n",
    "print(f\"Random Forest Train Accuracy: {accuracy_score(y_train, y_pred_train_rf):.2f}\")\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_score(y_test, y_pred_test_rf):.2f}\")\n",
    "\n",
    "# Print classification reports for both sets\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_pred_train_rf))\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_report(y_test, y_pred_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7ba6b-5ecc-4ae5-820e-53fc34697bb7",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea098424-11f7-49bb-a4a5-79b9cd39be2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.47\n",
      "Gradient Boosting Train Accuracy: 0.52\n",
      "Gradient Boosting Test Accuracy: 0.47\n",
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.61      0.06      0.11      1009\n",
      "     Burnout       0.51      0.98      0.68      1997\n",
      "  Depression       0.71      0.06      0.12       994\n",
      "\n",
      "    accuracy                           0.52      4000\n",
      "   macro avg       0.61      0.37      0.30      4000\n",
      "weighted avg       0.59      0.52      0.40      4000\n",
      "\n",
      "Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.39      0.05      0.09       269\n",
      "     Burnout       0.48      0.94      0.63       479\n",
      "  Depression       0.24      0.02      0.03       252\n",
      "\n",
      "    accuracy                           0.47      1000\n",
      "   macro avg       0.37      0.34      0.25      1000\n",
      "weighted avg       0.39      0.47      0.33      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GradientBoosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "gb_model.fit(X_train_encoded_np, y_train)\n",
    "\n",
    "# Predict the target on the test data\n",
    "y_pred_test_gb = gb_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Predict on both training and test sets\n",
    "y_pred_train_gb = gb_model.predict(X_train_encoded_np)\n",
    "y_pred_test_gb = gb_model.predict(X_test_encoded_np)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_test_gb)\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_gb:.2f}\")\n",
    "\n",
    "# Print accuracies for both sets\n",
    "print(f\"Gradient Boosting Train Accuracy: {accuracy_score(y_train, y_pred_train_gb):.2f}\")\n",
    "print(f\"Gradient Boosting Test Accuracy: {accuracy_score(y_test, y_pred_test_gb):.2f}\")\n",
    "\n",
    "# Print classification reports for both sets\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_pred_train_gb))\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_report(y_test, y_pred_test_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b4f9c-ddcf-4fa9-a192-43081c5f8b00",
   "metadata": {},
   "source": [
    "# Fixing class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7db333-349d-456a-85f2-ecfd12f630c3",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "26e79af4-7f2f-4e3e-955a-092ed58a8511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: Counter({'Burnout': 1997, 'Anxiety': 1009, 'Depression': 994})\n",
      "Class distribution after SMOTE: Counter({'Anxiety': 1997, 'Burnout': 1997, 'Depression': 1997})\n"
     ]
    }
   ],
   "source": [
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_encoded_np, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_balanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86601d-21da-40fa-9fa8-d237b2822d60",
   "metadata": {},
   "source": [
    "# Training models with balanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4882af9-e6b1-471c-9510-9a09e2425181",
   "metadata": {},
   "source": [
    "## Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e442275c-1b24-410a-8a63-abba9de75981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy (Balanced): 0.36\n",
      "Logistic Regression Test Accuracy (Balanced): 0.31\n",
      "Classification Report for Training Set (Balanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.36      0.37      0.36      1997\n",
      "     Burnout       0.37      0.28      0.32      1997\n",
      "  Depression       0.37      0.44      0.40      1997\n",
      "\n",
      "    accuracy                           0.36      5991\n",
      "   macro avg       0.36      0.36      0.36      5991\n",
      "weighted avg       0.36      0.36      0.36      5991\n",
      "\n",
      "Classification Report for Test Set (Balanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.26      0.35      0.30       269\n",
      "     Burnout       0.51      0.25      0.33       479\n",
      "  Depression       0.24      0.38      0.30       252\n",
      "\n",
      "    accuracy                           0.31      1000\n",
      "   macro avg       0.34      0.33      0.31      1000\n",
      "weighted avg       0.37      0.31      0.31      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on balanced data\n",
    "log_reg.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on the balanced training set\n",
    "y_pred_train_balanced_log_reg = log_reg.predict(X_train_balanced)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test_balanced_log_reg = log_reg.predict(X_test_encoded_np)\n",
    "\n",
    "# Evaluate accuracy on the training set (to check for overfitting)\n",
    "train_accuracy = accuracy_score(y_train_balanced, y_pred_train_balanced_log_reg)\n",
    "print(f\"Logistic Regression Train Accuracy (Balanced): {train_accuracy:.2f}\")\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_balanced_log_reg)\n",
    "print(f\"Logistic Regression Test Accuracy (Balanced): {test_accuracy:.2f}\")\n",
    "\n",
    "# Print classification report for the training set\n",
    "print(\"Classification Report for Training Set (Balanced):\")\n",
    "print(classification_report(y_train_balanced, y_pred_train_balanced_log_reg, zero_division=1))\n",
    "\n",
    "# Print classification report for the test set\n",
    "print(\"Classification Report for Test Set (Balanced):\")\n",
    "print(classification_report(y_test, y_pred_test_balanced_log_reg, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6415f32-c9a2-459e-8ba8-0308187eb25e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8f17378-2a62-4ac0-8614-fa6d0cbc986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy (Balanced): 0.98\n",
      "Random Forest Test Accuracy (Balanced): 0.35\n",
      "Classification Report for Training Set (Balanced - Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.99      0.99      0.99      1997\n",
      "     Burnout       0.98      0.98      0.98      1997\n",
      "  Depression       0.98      0.98      0.98      1997\n",
      "\n",
      "    accuracy                           0.98      5991\n",
      "   macro avg       0.98      0.98      0.98      5991\n",
      "weighted avg       0.98      0.98      0.98      5991\n",
      "\n",
      "Classification Report for Test Set (Balanced - Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.28      0.33      0.30       269\n",
      "     Burnout       0.48      0.42      0.44       479\n",
      "  Depression       0.24      0.25      0.24       252\n",
      "\n",
      "    accuracy                           0.35      1000\n",
      "   macro avg       0.33      0.33      0.33      1000\n",
      "weighted avg       0.36      0.35      0.36      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on balanced data\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on the balanced training set\n",
    "y_pred_train_balanced_rf = rf_model.predict(X_train_balanced)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test_balanced_rf = rf_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Evaluate accuracy on the training set (to check for overfitting)\n",
    "train_accuracy_rf = accuracy_score(y_train_balanced, y_pred_train_balanced_rf)\n",
    "print(f\"Random Forest Train Accuracy (Balanced): {train_accuracy_rf:.2f}\")\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred_test_balanced_rf)\n",
    "print(f\"Random Forest Test Accuracy (Balanced): {test_accuracy_rf:.2f}\")\n",
    "\n",
    "# Print classification report for the training set\n",
    "print(\"Classification Report for Training Set (Balanced - Random Forest):\")\n",
    "print(classification_report(y_train_balanced, y_pred_train_balanced_rf, zero_division=1))\n",
    "\n",
    "# Print classification report for the test set\n",
    "print(\"Classification Report for Test Set (Balanced - Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_test_balanced_rf, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e1d3f-3498-4529-9404-ffd79c4a617c",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7b3c57b-02c3-4068-8a07-0fdb103c9462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Train Accuracy (Balanced): 0.56\n",
      "Gradient Boosting Test Accuracy (Balanced): 0.36\n",
      "Classification Report for Training Set (Balanced - Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.58      0.54      0.56      1997\n",
      "     Burnout       0.54      0.62      0.58      1997\n",
      "  Depression       0.58      0.53      0.55      1997\n",
      "\n",
      "    accuracy                           0.56      5991\n",
      "   macro avg       0.57      0.56      0.56      5991\n",
      "weighted avg       0.57      0.56      0.56      5991\n",
      "\n",
      "Classification Report for Test Set (Balanced - Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.22      0.22      0.22       269\n",
      "     Burnout       0.49      0.54      0.51       479\n",
      "  Depression       0.22      0.18      0.20       252\n",
      "\n",
      "    accuracy                           0.36      1000\n",
      "   macro avg       0.31      0.31      0.31      1000\n",
      "weighted avg       0.35      0.36      0.36      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting on balanced data\n",
    "gb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on the balanced training set\n",
    "y_pred_train_balanced_gb = gb_model.predict(X_train_balanced)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test_balanced_gb = gb_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Evaluate accuracy on the training set (to check for overfitting)\n",
    "train_accuracy_gb = accuracy_score(y_train_balanced, y_pred_train_balanced_gb)\n",
    "print(f\"Gradient Boosting Train Accuracy (Balanced): {train_accuracy_gb:.2f}\")\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy_gb = accuracy_score(y_test, y_pred_test_balanced_gb)\n",
    "print(f\"Gradient Boosting Test Accuracy (Balanced): {test_accuracy_gb:.2f}\")\n",
    "\n",
    "# Print classification report for the training set\n",
    "print(\"Classification Report for Training Set (Balanced - Gradient Boosting):\")\n",
    "print(classification_report(y_train_balanced, y_pred_train_balanced_gb, zero_division=1))\n",
    "\n",
    "# Print classification report for the test set\n",
    "print(\"Classification Report for Test Set (Balanced - Gradient Boosting):\")\n",
    "print(classification_report(y_test, y_pred_test_balanced_gb, zero_division=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269565b3-8f00-4994-8771-72e7517f1596",
   "metadata": {},
   "source": [
    "# Hyper parameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53c409-3947-47ca-9bc2-324f01d0dfd8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c3f7d46-2122-489c-bbd7-7f0d4a3059ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best Random Forest Hyperparameters: {'bootstrap': False, 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 70}\n",
      "Tuned Random Forest Accuracy: 0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.29      0.34      0.31       269\n",
      "     Burnout       0.46      0.39      0.43       479\n",
      "  Depression       0.23      0.25      0.24       252\n",
      "\n",
      "    accuracy                           0.34      1000\n",
      "   macro avg       0.33      0.33      0.33      1000\n",
      "weighted avg       0.36      0.34      0.35      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 70],  # Number of trees\n",
    "    'max_depth': [10, 15],           # Maximum depth of trees\n",
    "    'min_samples_split': [8, 16],     # Minimum number of samples to split an internal node\n",
    "    'min_samples_leaf': [2,4],      # Minimum number of samples at a leaf node\n",
    "    'bootstrap': [True, False]       # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV for Random Forest\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Random Forest Hyperparameters:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_train_rf_tuned = best_rf_model.predict(X_train_encoded_np)\n",
    "y_pred_test_rf_tuned  = best_rf_model.predict(X_test_encoded_np)\n",
    "\n",
    "# If the model performance in the train set is >>>> performance in the test -> Model overffited\n",
    "# Print accuracy and classification report\n",
    "print(f\"Tuned Random Forest Accuracy: {accuracy_score(y_test, y_pred_test_rf_tuned):.2f}\")\n",
    "print(classification_report(y_test, y_pred_test_rf_tuned, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f122c-339b-42ae-8296-d5bdc8d76b30",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5a367c69-ebe6-42c7-b2f9-3ed09ade057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best Gradient Boosting Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150, 'subsample': 0.8}\n",
      "Tuned Gradient Boosting Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.28      0.19      0.23       269\n",
      "     Burnout       0.48      0.66      0.55       479\n",
      "  Depression       0.24      0.15      0.19       252\n",
      "\n",
      "    accuracy                           0.41      1000\n",
      "   macro avg       0.33      0.33      0.32      1000\n",
      "weighted avg       0.37      0.41      0.37      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid for Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 150],  # Smaller number of boosting rounds\n",
    "    'max_depth': [3, 5],  # Limit depth to prevent overfitting\n",
    "    'learning_rate': [0.05, 0.1],  # Smaller learning rate\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV for Gradient Boosting\n",
    "grid_search_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_gb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Gradient Boosting Hyperparameters:\", grid_search_gb.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_gb_model = grid_search_gb.best_estimator_\n",
    "y_pred_test_gb_tuned = best_gb_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Tuned Gradient Boosting Accuracy: {accuracy_score(y_test, y_pred_test_gb_tuned):.2f}\")\n",
    "print(classification_report(y_test, y_pred_test_gb_tuned, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f421b0-de02-45ac-b6e6-e5cd107033a6",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "afcb9502-8fbc-44c4-b8fa-c9203cecf39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.34\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.24      0.27      0.26       269\n",
      "     Burnout       0.47      0.43      0.45       479\n",
      "  Depression       0.23      0.24      0.24       252\n",
      "\n",
      "    accuracy                           0.34      1000\n",
      "   macro avg       0.32      0.32      0.32      1000\n",
      "weighted avg       0.35      0.34      0.35      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the balanced training data\n",
    "dt_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict the target on the test data\n",
    "y_pred_test_dt = dt_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Evaluate the Decision Tree's accuracy and performance\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test, y_pred_test_dt):.2f}\")\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_dt, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1290e03-b474-4c1c-a3ec-e1610105485c",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19577c0f-8e59-4ac9-acb9-2987dc0b179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.36\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.30      0.40      0.34       269\n",
      "     Burnout       0.50      0.35      0.41       479\n",
      "  Depression       0.28      0.35      0.31       252\n",
      "\n",
      "    accuracy                           0.36      1000\n",
      "   macro avg       0.36      0.37      0.36      1000\n",
      "weighted avg       0.39      0.36      0.37      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Support Vector Machine model\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# Train the SVM model on the balanced training data\n",
    "svm_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict the target on the test data\n",
    "y_pred_test_svm = svm_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Evaluate the SVM model's accuracy and performance\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_test_svm):.2f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_svm, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab3dd3-2e60-4160-8d4a-df7b46641de0",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "76b515a9-133c-4a10-bc50-f853a7c967fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Employee_ID', 'Age', 'Gender', 'Job_Role', 'Industry',\n",
      "       'Years_of_Experience', 'Work_Location', 'Hours_Worked_Per_Week',\n",
      "       'Number_of_Virtual_Meetings', 'Work_Life_Balance_Rating',\n",
      "       'Stress_Level', 'Mental_Health_Condition',\n",
      "       'Access_to_Mental_Health_Resources', 'Productivity_Change',\n",
      "       'Social_Isolation_Rating', 'Satisfaction_with_Remote_Work',\n",
      "       'Company_Support_for_Remote_Work', 'Physical_Activity', 'Sleep_Quality',\n",
      "       'Region'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a5a0c508-ebaa-4ddc-912a-439fe687868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gender', 'Job_Role', 'Industry', 'Years_of_Experience',\n",
      "       'Hours_Worked_Per_Week', 'Number_of_Virtual_Meetings',\n",
      "       'Work_Life_Balance_Rating', 'Stress_Level',\n",
      "       'Access_to_Mental_Health_Resources', 'Social_Isolation_Rating',\n",
      "       'Satisfaction_with_Remote_Work', 'Company_Support_for_Remote_Work',\n",
      "       'Physical_Activity', 'Sleep_Quality', 'Region',\n",
      "       'Stress_Work_Location_Hybrid', 'Stress_Work_Location_Onsite',\n",
      "       'Stress_Work_Location_Remote', 'WorkLifeBalance_Experience',\n",
      "       'Work_Location_Hybrid', 'Work_Location_Onsite', 'Work_Location_Remote',\n",
      "       'Mental_Health_Condition_Anxiety', 'Mental_Health_Condition_Burnout',\n",
      "       'Mental_Health_Condition_Depression', 'Productivity_Change_Decrease',\n",
      "       'Productivity_Change_Increase', 'Productivity_Change_No Change',\n",
      "       'Age_Binned_Young', 'Age_Binned_Mid', 'Age_Binned_Senior'],\n",
      "      dtype='object')\n",
      "X_train_encoded_np shape: (4000, 13)\n",
      "X_test_encoded_np shape: (1000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Create interaction terms between Stress_Level and Work_Location categories without encoding\n",
    "df['Stress_Work_Location_Hybrid'] = df['Stress_Level'] * (df['Work_Location'] == 'Hybrid').astype(int)\n",
    "df['Stress_Work_Location_Onsite'] = df['Stress_Level'] * (df['Work_Location'] == 'Onsite').astype(int)\n",
    "df['Stress_Work_Location_Remote'] = df['Stress_Level'] * (df['Work_Location'] == 'Remote').astype(int)\n",
    "\n",
    "# Continue with WorkLifeBalance_Experience as usual\n",
    "df['WorkLifeBalance_Experience'] = df['Work_Life_Balance_Rating'] * df['Years_of_Experience']\n",
    "\n",
    "# Bin 'Age' into categories: Young (<=30), Mid (30-50), Senior (50+)\n",
    "df['Age_Binned'] = pd.cut(df['Age'], bins=[0, 30, 50, 100], labels=['Young', 'Mid', 'Senior'])\n",
    "\n",
    "# Drop unnecessary columns to reduce model complexity\n",
    "df = df.drop(['Employee_ID', 'Age'], axis=1)  # Ensure columns like 'Age' are not being used if transformed\n",
    "\n",
    "# Re-run the encoding for new features\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "# Print the columns to check the final state\n",
    "print(df_encoded.columns)\n",
    "\n",
    "# Prepare the features and target for training again\n",
    "X = df_encoded.drop('Mental_Health_Condition_Anxiety', axis=1)  # Be sure of the actual label in the column\n",
    "y = df_encoded['Mental_Health_Condition_Anxiety']\n",
    "\n",
    "# Split the data again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE again to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# List of categorical columns that need encoding\n",
    "categorical_cols = ['Job_Role', 'Gender']  # Update based on your df_encoded columns\n",
    "\n",
    "# Adjust the list of categorical and numerical columns based on X_train\n",
    "numerical_cols = ['Hours_Worked_Per_Week', 'Years_of_Experience']  # Update to match your df_encoded\n",
    "\n",
    "# Create ColumnTransformer for encoding categorical features and scaling numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_cols),  # OneHotEncode categorical features\n",
    "        ('num', StandardScaler(), numerical_cols)    # Scale numerical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply transformations to training and testing sets\n",
    "X_train_encoded_np = preprocessor.fit_transform(X_train)  # Corrected variable name\n",
    "X_test_encoded_np = preprocessor.transform(X_test)        # Corrected variable name\n",
    "\n",
    "# Check the shape after encoding\n",
    "print(\"X_train_encoded_np shape:\", X_train_encoded_np.shape)\n",
    "print(\"X_test_encoded_np shape:\", X_test_encoded_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc75fa-8246-4ebc-b11a-132fc6555a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 70],  # Number of trees\n",
    "    'max_depth': [10, 15],           # Maximum depth of trees\n",
    "    'min_samples_split': [8, 16],     # Minimum number of samples to split an internal node\n",
    "    'min_samples_leaf': [2,4],      # Minimum number of samples at a leaf node\n",
    "    'bootstrap': [True, False]       # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV for Random Forest\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Random Forest Hyperparameters:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_train_rf_tuned = best_rf_model.predict(X_train_encoded_np)\n",
    "y_pred_test_rf_tuned  = best_rf_model.predict(X_test_encoded_np)\n",
    "\n",
    "# If the model performance in the train set is >>>> performance in the test -> Model overffited\n",
    "# Print accuracy and classification report\n",
    "print(f\"Tuned Random Forest Accuracy: {accuracy_score(y_test, y_pred_test_rf_tuned):.2f}\")\n",
    "print(classification_report(y_test, y_pred_test_rf_tuned, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db3ca1-630a-44ad-b636-a9f586c4fc97",
   "metadata": {},
   "source": [
    "## Re-Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324d0e6-0879-46fa-aad9-aa5b04dc7ca1",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "376b4ca8-d43d-4145-85c2-35b0943aae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_encoded_np shape: (4000, 13)\n",
      "X_test_encoded_np shape: (1000, 13)\n",
      "Tuned Random Forest Train Accuracy: 0.99\n",
      "Tuned Random Forest Test Accuracy: 0.65\n",
      "Classification Report for Training Set (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      2991\n",
      "        True       0.98      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.99      4000\n",
      "   macro avg       0.99      0.98      0.98      4000\n",
      "weighted avg       0.99      0.99      0.99      4000\n",
      "\n",
      "Classification Report for Test Set (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.83      0.78       731\n",
      "        True       0.27      0.17      0.21       269\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.50      0.50      0.49      1000\n",
      "weighted avg       0.61      0.65      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test sets have the same features\n",
    "print(f\"X_train_encoded_np shape: {X_train_encoded_np.shape}\")\n",
    "print(f\"X_test_encoded_np shape: {X_test_encoded_np.shape}\")\n",
    "\n",
    "# Re-fit the RandomForestClassifier using the current set of 13 features\n",
    "best_rf_model = RandomForestClassifier(random_state=42)\n",
    "best_rf_model.fit(X_train_encoded_np, y_train)\n",
    "\n",
    "# Predictions on both the training and test sets\n",
    "y_pred_train_rf_tuned = best_rf_model.predict(X_train_encoded_np)\n",
    "y_pred_test_rf_tuned = best_rf_model.predict(X_test_encoded_np)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Tuned Random Forest Train Accuracy: {accuracy_score(y_train, y_pred_train_rf_tuned):.2f}\")\n",
    "print(f\"Tuned Random Forest Test Accuracy: {accuracy_score(y_test, y_pred_test_rf_tuned):.2f}\")\n",
    "\n",
    "# Print classification report for both training and test sets\n",
    "print(\"Classification Report for Training Set (Random Forest):\")\n",
    "print(classification_report(y_train, y_pred_train_rf_tuned))\n",
    "print(\"Classification Report for Test Set (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_test_rf_tuned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9deb1a8-ead0-47f7-8ee3-08c59ea93b53",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2af52548-9f1e-42e0-94f8-f0b466976552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Train Accuracy: 0.75\n",
      "Gradient Boosting Test Accuracy: 0.73\n",
      "Classification Report for Training Set (Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      1.00      0.86      2991\n",
      "        True       1.00      0.00      0.01      1009\n",
      "\n",
      "    accuracy                           0.75      4000\n",
      "   macro avg       0.87      0.50      0.43      4000\n",
      "weighted avg       0.81      0.75      0.64      4000\n",
      "\n",
      "Classification Report for Test Set (Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      1.00      0.84       731\n",
      "        True       1.00      0.00      0.00       269\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.87      0.50      0.42      1000\n",
      "weighted avg       0.80      0.73      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "gb_model.fit(X_train_encoded_np, y_train)\n",
    "\n",
    "# Predict on both the training and test sets\n",
    "y_pred_train_gb = gb_model.predict(X_train_encoded_np)  # Predictions on training set\n",
    "y_pred_test_gb = gb_model.predict(X_test_encoded_np)    # Predictions on test set\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Gradient Boosting Train Accuracy: {accuracy_score(y_train, y_pred_train_gb):.2f}\")\n",
    "print(f\"Gradient Boosting Test Accuracy: {accuracy_score(y_test, y_pred_test_gb):.2f}\")\n",
    "\n",
    "# Print classification report for both training and test sets with zero_division handling\n",
    "print(\"Classification Report for Training Set (Gradient Boosting):\")\n",
    "print(classification_report(y_train, y_pred_train_gb, zero_division=1))\n",
    "\n",
    "print(\"Classification Report for Test Set (Gradient Boosting):\")\n",
    "print(classification_report(y_test, y_pred_test_gb, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee5d27-1bdd-4722-b586-b8009b59f6fc",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1b960822-145a-413c-b679-e7f57e033d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Accuracy: 0.99\n",
      "Decision Tree Test Accuracy: 0.60\n",
      "Classification Report for Training Set (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99      2991\n",
      "        True       1.00      0.95      0.97      1009\n",
      "\n",
      "    accuracy                           0.99      4000\n",
      "   macro avg       0.99      0.97      0.98      4000\n",
      "weighted avg       0.99      0.99      0.99      4000\n",
      "\n",
      "Classification Report for Test Set (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.72      0.72       731\n",
      "        True       0.26      0.27      0.26       269\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.49      0.49      0.49      1000\n",
      "weighted avg       0.60      0.60      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "dt_model.fit(X_train_encoded_np, y_train)\n",
    "\n",
    "# Predict on both the training and test sets\n",
    "y_pred_train_dt = dt_model.predict(X_train_encoded_np)  # Predictions on training set\n",
    "y_pred_test_dt = dt_model.predict(X_test_encoded_np)    # Predictions on test set\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Decision Tree Train Accuracy: {accuracy_score(y_train, y_pred_train_dt):.2f}\")\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_score(y_test, y_pred_test_dt):.2f}\")\n",
    "\n",
    "# Print classification report for both training and test sets\n",
    "print(\"Classification Report for Training Set (Decision Tree):\")\n",
    "print(classification_report(y_train, y_pred_train_dt))\n",
    "print(\"Classification Report for Test Set (Decision Tree):\")\n",
    "print(classification_report(y_test, y_pred_test_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aac59c-0516-4bb2-a567-4d5a7aaab6cb",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "50573e95-2137-41ec-9546-fc51a3ea8e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Train Accuracy: 0.75\n",
      "SVC Test Accuracy: 0.73\n",
      "Classification Report for Training Set (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      1.00      0.86      2991\n",
      "        True       1.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.75      4000\n",
      "   macro avg       0.87      0.50      0.43      4000\n",
      "weighted avg       0.81      0.75      0.64      4000\n",
      "\n",
      "Classification Report for Test Set (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      1.00      0.84       731\n",
      "        True       1.00      0.00      0.00       269\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.87      0.50      0.42      1000\n",
      "weighted avg       0.80      0.73      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "svc_model = SVC()\n",
    "\n",
    "# Train the model on the training data\n",
    "svc_model.fit(X_train_encoded_np, y_train)\n",
    "\n",
    "# Predict on both the training and test sets\n",
    "y_pred_train_svc = svc_model.predict(X_train_encoded_np)  # Predictions on training set\n",
    "y_pred_test_svc = svc_model.predict(X_test_encoded_np)    # Predictions on test set\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"SVC Train Accuracy: {accuracy_score(y_train, y_pred_train_svc):.2f}\")\n",
    "print(f\"SVC Test Accuracy: {accuracy_score(y_test, y_pred_test_svc):.2f}\")\n",
    "\n",
    "# Print classification report for both training and test sets with zero_division handling for SVC\n",
    "print(\"Classification Report for Training Set (SVC):\")\n",
    "print(classification_report(y_train, y_pred_train_svc, zero_division=1))\n",
    "\n",
    "print(\"Classification Report for Test Set (SVC):\")\n",
    "print(classification_report(y_test, y_pred_test_svc, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "06c0a381-1e82-4e8e-b6b5-0af088e0bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_encoded_np, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "70788edc-eb77-4d1e-9451-6e1b818d7514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy with Class Weights: 0.84\n",
      "Random Forest Test Accuracy with Class Weights: 0.55\n",
      "Classification Report for Training Set (Weighted Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.78      0.83      2991\n",
      "        True       0.80      0.89      0.84      2991\n",
      "\n",
      "    accuracy                           0.84      5982\n",
      "   macro avg       0.84      0.84      0.83      5982\n",
      "weighted avg       0.84      0.84      0.83      5982\n",
      "\n",
      "Classification Report for Test Set (Weighted Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.61      0.67       731\n",
      "        True       0.27      0.39      0.32       269\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.50      0.50      0.49      1000\n",
      "weighted avg       0.61      0.55      0.57      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Random Forest with class weights\n",
    "rf_with_class_weights = RandomForestClassifier(\n",
    "    class_weight='balanced', \n",
    "    random_state=42, \n",
    "    n_estimators=100, \n",
    "    max_depth=10\n",
    ")\n",
    "\n",
    "# Train the model on the balanced training data\n",
    "rf_with_class_weights.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on the balanced training set and test set\n",
    "y_pred_train_rf_weighted = rf_with_class_weights.predict(X_train_balanced)\n",
    "y_pred_test_rf_weighted  = rf_with_class_weights.predict(X_test_encoded_np)\n",
    "\n",
    "# Evaluate the model on both sets\n",
    "train_accuracy_weighted = accuracy_score(y_train_balanced, y_pred_train_rf_weighted)\n",
    "test_accuracy_weighted = accuracy_score(y_test, y_pred_test_rf_weighted)\n",
    "\n",
    "# Print accuracy for both sets\n",
    "print(f\"Random Forest Train Accuracy with Class Weights: {train_accuracy_weighted:.2f}\")\n",
    "print(f\"Random Forest Test Accuracy with Class Weights: {test_accuracy_weighted:.2f}\")\n",
    "\n",
    "# Print classification reports for both sets\n",
    "print(\"Classification Report for Training Set (Weighted Random Forest):\")\n",
    "print(classification_report(y_train_balanced, y_pred_train_rf_weighted, zero_division=1))\n",
    "\n",
    "print(\"Classification Report for Test Set (Weighted Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_test_rf_weighted, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ccd52-61b8-4a21-8729-792c34b76d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
